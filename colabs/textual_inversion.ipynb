{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
        "from skimage import io, transform\n",
        "from tqdm import tqdm\n",
        "auth.authenticate_user()\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "MP33UkoivCOl",
        "outputId": "b8c3a7cd-213e-4597-c3f0-dfb94fb4be42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/49.5 kB\u001b[0m \u001b[31m617.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m755.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ef3d6eb44aed>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade -q gspread'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cv2_imshow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cv_imshow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodule_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mcv_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodule_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpreviously_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mC_BUILTIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/imp.py\u001b[0m in \u001b[0;36mload_package\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__collect_extra_submodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m__load_extra_py_code_for_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra Python code for\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m__load_extra_py_code_for_module\u001b[0;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mnative_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpy_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menable_debug_print\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "worksheet = gc.open('hands and palms loras').worksheet('scale1').get(\"A2:I625\")\n",
        "df = pd.DataFrame.from_records(worksheet)\n",
        "df = df.rename({0:'rank', 1:'checkpoint', 2:'side',3:'gender', 4:'hand', 5:'image', 6: 'bad', 7:'ok', 8:'good'}, axis=1)\n",
        "df = df.loc[df['bad']==\"1\"]\n",
        "\n",
        "for index, row in tqdm([(index, row) for (index, row) in df.iterrows()]):\n",
        "  if row['rank'] != 'None':\n",
        "    path = f'/content/drive/MyDrive/LoRA/inference/hands and palms r{row[\"rank\"]} lora/{row[\"side\"]}_of_fair-skinned_{row[\"gender\"]}_{row[\"hand\"]}_hand_chkpt{row[\"checkpoint\"]}_steps30_{row[\"image\"]}.png'\n",
        "  else:\n",
        "    path = f'/content/drive/MyDrive/LoRA/inference/hands and palms r{row[\"rank\"]} lora/{row[\"side\"]}_of_fair-skinned_{row[\"gender\"]}_{row[\"hand\"]}_hand_chkpt5000_steps30_{row[\"image\"]}.png'\n",
        "  shutil.copy(path, '/content/drive/MyDrive/cs236 project/anybadhand/'+os.path.basename(path))\n",
        "  shutil.copy(path, '/content/drive/MyDrive/cs236 project/bad11k/'+os.path.basename(path))"
      ],
      "metadata": {
        "id": "zm0pJUIEvzVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/cs236 project/anybadhand\""
      ],
      "metadata": {
        "id": "kltd_zpHyH_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install git+https://github.com/huggingface/diffusers\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "%cd diffusers/examples/textual_inversion"
      ],
      "metadata": {
        "id": "2FSc1c1gw3ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e99165b-3024-40ee-c437-b6cd804cf1fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting git+https://github.com/huggingface/diffusers\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-f1btfpkt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-f1btfpkt\n",
            "  Resolved https://github.com/huggingface/diffusers to commit ab6672fecd45aef292c69476aeb0275a2b5b418b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (6.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.25.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.25.0.dev0-py3-none-any.whl size=1775571 sha256=cfe3e78239df40f6d7f2307569984caf0c38f0378ae48fb071684584ef4c2629\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zb85dkmg/wheels/f7/7d/99/d361489e5762e3464b3811bc629e94cf5bf5ef44dd5c3c4d52\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.25.0.dev0\n",
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 47451, done.\u001b[K\n",
            "remote: Counting objects: 100% (1101/1101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (434/434), done.\u001b[K\n",
            "remote: Total 47451 (delta 745), reused 854 (delta 600), pack-reused 46350\u001b[K\n",
            "Receiving objects: 100% (47451/47451), 31.59 MiB | 19.60 MiB/s, done.\n",
            "Resolving deltas: 100% (35037/35037), done.\n",
            "/content/diffusers/examples/textual_inversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWiYTe7GzG1C",
        "outputId": "ec36b934-69c3-4313-eae9-c401baac59c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate>=0.16.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/265.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/265.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m256.0/265.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.16.0+cu118)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.35.2)\n",
            "Collecting ftfy (from -r requirements.txt (line 4))\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.14.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 4)) (0.2.12)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: ftfy, accelerate\n",
            "Successfully installed accelerate-0.25.0 ftfy-6.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --train_data_dir='/content/drive/MyDrive/cs236 project cornell/anybadhand/' \\\n",
        "  --learnable_property=\"object\" \\\n",
        "  --placeholder_token=\"<anybadhand>\" \\\n",
        "  --initializer_token=\"hand\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=4 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --learning_rate=5.0e-04 \\\n",
        "  --scale_lr \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"/content/drive/MyDrive/cs236 project cornell/textual_inversion_any_bad_hand\""
      ],
      "metadata": {
        "id": "2VH788mwAXsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --train_data_dir='/content/drive/MyDrive/cs236 project cornell/badcontexthand/' \\\n",
        "  --learnable_property=\"object\" \\\n",
        "  --placeholder_token=\"<badcontexthand>\" \\\n",
        "  --initializer_token=\"hand\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=4 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --learning_rate=5.0e-04 \\\n",
        "  --scale_lr \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"/content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand\""
      ],
      "metadata": {
        "id": "CjeE8S1Jw8Ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f9d72b-5768-4b68-b8df-39551b0fcb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-12-06 01:05:53.535080: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-06 01:05:53.535139: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-06 01:05:53.535179: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-06 01:05:55.163772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/06/2023 01:05:56 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "tokenizer/tokenizer_config.json: 100% 806/806 [00:00<00:00, 4.35MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 14.0MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 12.7MB/s]\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 2.89MB/s]\n",
            "scheduler/scheduler_config.json: 100% 308/308 [00:00<00:00, 1.41MB/s]\n",
            "{'sample_max_value', 'prediction_type', 'thresholding', 'clip_sample_range', 'variance_type', 'dynamic_thresholding_ratio', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "text_encoder/config.json: 100% 617/617 [00:00<00:00, 2.93MB/s]\n",
            "model.safetensors: 100% 492M/492M [00:02<00:00, 244MB/s]\n",
            "vae/config.json: 100% 547/547 [00:00<00:00, 3.21MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 253MB/s]\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "unet/config.json: 100% 743/743 [00:00<00:00, 4.22MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:17<00:00, 198MB/s]\n",
            "{'time_cond_proj_dim', 'mid_block_only_cross_attention', 'time_embedding_type', 'use_linear_projection', 'transformer_layers_per_block', 'dropout', 'resnet_time_scale_shift', 'encoder_hid_dim', 'encoder_hid_dim_type', 'conv_out_kernel', 'dual_cross_attention', 'class_embeddings_concat', 'cross_attention_norm', 'class_embed_type', 'only_cross_attention', 'num_attention_heads', 'num_class_embeds', 'time_embedding_act_fn', 'projection_class_embeddings_input_dim', 'mid_block_type', 'upcast_attention', 'resnet_skip_time_act', 'resnet_out_scale_factor', 'time_embedding_dim', 'addition_embed_type', 'addition_embed_type_num_heads', 'conv_in_kernel', 'reverse_transformer_layers_per_block', 'addition_time_embed_dim', 'attention_type', 'timestep_post_act'} was not found in config. Values will be initialized to default values.\n",
            "12/06/2023 01:06:40 - INFO - __main__ - ***** Running training *****\n",
            "12/06/2023 01:06:40 - INFO - __main__ -   Num examples = 8400\n",
            "12/06/2023 01:06:40 - INFO - __main__ -   Num Epochs = 2\n",
            "12/06/2023 01:06:40 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "12/06/2023 01:06:40 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "12/06/2023 01:06:40 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "12/06/2023 01:06:40 - INFO - __main__ -   Total optimization steps = 3000\n",
            "Steps:  17% 500/3000 [31:13<2:34:17,  3.70s/it, loss=0.0788, lr=0.002]12/06/2023 01:37:54 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 01:37:54 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500\n",
            "12/06/2023 01:38:03 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500/model.safetensors\n",
            "12/06/2023 01:38:12 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500/optimizer.bin\n",
            "12/06/2023 01:38:12 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500/scheduler.bin\n",
            "12/06/2023 01:38:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500/sampler.bin\n",
            "12/06/2023 01:38:13 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500/random_states_0.pkl\n",
            "12/06/2023 01:38:13 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-500\n",
            "Steps:  33% 1000/3000 [1:02:31<2:03:13,  3.70s/it, loss=0.0531, lr=0.002]12/06/2023 02:09:11 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 02:09:11 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000\n",
            "12/06/2023 02:09:17 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000/model.safetensors\n",
            "12/06/2023 02:09:20 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000/optimizer.bin\n",
            "12/06/2023 02:09:20 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000/scheduler.bin\n",
            "12/06/2023 02:09:20 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000/sampler.bin\n",
            "12/06/2023 02:09:20 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000/random_states_0.pkl\n",
            "12/06/2023 02:09:20 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1000\n",
            "Steps:  50% 1500/3000 [1:33:30<1:32:34,  3.70s/it, loss=0.131, lr=0.002]12/06/2023 02:40:10 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 02:40:10 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500\n",
            "12/06/2023 02:40:12 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500/model.safetensors\n",
            "12/06/2023 02:40:13 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500/optimizer.bin\n",
            "12/06/2023 02:40:13 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500/scheduler.bin\n",
            "12/06/2023 02:40:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500/sampler.bin\n",
            "12/06/2023 02:40:13 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500/random_states_0.pkl\n",
            "12/06/2023 02:40:13 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-1500\n",
            "Steps:  67% 2000/3000 [2:04:30<1:01:39,  3.70s/it, loss=0.0376, lr=0.002]12/06/2023 03:11:11 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 03:11:11 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000\n",
            "12/06/2023 03:11:13 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000/model.safetensors\n",
            "12/06/2023 03:11:14 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000/optimizer.bin\n",
            "12/06/2023 03:11:14 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000/scheduler.bin\n",
            "12/06/2023 03:11:14 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000/sampler.bin\n",
            "12/06/2023 03:11:14 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000/random_states_0.pkl\n",
            "12/06/2023 03:11:14 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2000\n",
            "Steps:  83% 2500/3000 [2:35:24<30:47,  3.69s/it, loss=0.232, lr=0.002]12/06/2023 03:42:05 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 03:42:05 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500\n",
            "12/06/2023 03:42:07 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500/model.safetensors\n",
            "12/06/2023 03:42:08 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500/optimizer.bin\n",
            "12/06/2023 03:42:08 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500/scheduler.bin\n",
            "12/06/2023 03:42:08 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500/sampler.bin\n",
            "12/06/2023 03:42:08 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500/random_states_0.pkl\n",
            "12/06/2023 03:42:08 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-2500\n",
            "Steps: 100% 3000/3000 [3:06:27<00:00,  3.70s/it, loss=0.154, lr=0.002]12/06/2023 04:13:07 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 04:13:07 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000\n",
            "12/06/2023 04:13:09 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000/model.safetensors\n",
            "12/06/2023 04:13:10 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000/optimizer.bin\n",
            "12/06/2023 04:13:10 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000/scheduler.bin\n",
            "12/06/2023 04:13:10 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000/sampler.bin\n",
            "12/06/2023 04:13:10 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000/random_states_0.pkl\n",
            "12/06/2023 04:13:10 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_badcontexthand/checkpoint-3000\n",
            "Steps: 100% 3000/3000 [3:06:30<00:00,  3.70s/it, loss=0.12, lr=0.002] 12/06/2023 04:13:10 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 3000/3000 [3:06:30<00:00,  3.73s/it, loss=0.12, lr=0.002]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --train_data_dir='/content/drive/MyDrive/cs236 project cornell/bad11k/' \\\n",
        "  --learnable_property=\"object\" \\\n",
        "  --placeholder_token=\"<bad11khand>\" \\\n",
        "  --initializer_token=\"hand\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=4 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --learning_rate=5.0e-04 \\\n",
        "  --scale_lr \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"/content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand\" \\\n",
        "  --resume_from_checkpoint='latest'"
      ],
      "metadata": {
        "id": "kBfYUjTk1mwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60da7799-e6c2-4fff-c8cf-5ce5b0586537"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-12-06 11:35:35.883541: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-06 11:35:35.883606: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-06 11:35:35.883639: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-06 11:35:36.932899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/06/2023 11:35:37 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "tokenizer/tokenizer_config.json: 100% 806/806 [00:00<00:00, 3.97MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.27MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 3.93MB/s]\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 2.66MB/s]\n",
            "scheduler/scheduler_config.json: 100% 308/308 [00:00<00:00, 1.45MB/s]\n",
            "{'dynamic_thresholding_ratio', 'prediction_type', 'sample_max_value', 'timestep_spacing', 'thresholding', 'clip_sample_range', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "text_encoder/config.json: 100% 617/617 [00:00<00:00, 3.16MB/s]\n",
            "model.safetensors: 100% 492M/492M [00:02<00:00, 225MB/s]\n",
            "vae/config.json: 100% 547/547 [00:00<00:00, 3.46MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 268MB/s]\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "unet/config.json: 100% 743/743 [00:00<00:00, 2.90MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:22<00:00, 151MB/s]\n",
            "{'conv_in_kernel', 'encoder_hid_dim_type', 'mid_block_type', 'transformer_layers_per_block', 'time_embedding_act_fn', 'time_embedding_dim', 'timestep_post_act', 'addition_embed_type', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'projection_class_embeddings_input_dim', 'num_attention_heads', 'num_class_embeds', 'cross_attention_norm', 'encoder_hid_dim', 'resnet_time_scale_shift', 'class_embed_type', 'dual_cross_attention', 'use_linear_projection', 'dropout', 'class_embeddings_concat', 'upcast_attention', 'addition_time_embed_dim', 'reverse_transformer_layers_per_block', 'conv_out_kernel', 'resnet_out_scale_factor', 'only_cross_attention', 'time_embedding_type', 'time_cond_proj_dim', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "12/06/2023 11:36:29 - INFO - __main__ - ***** Running training *****\n",
            "12/06/2023 11:36:29 - INFO - __main__ -   Num examples = 17600\n",
            "12/06/2023 11:36:29 - INFO - __main__ -   Num Epochs = 1\n",
            "12/06/2023 11:36:29 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "12/06/2023 11:36:29 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "12/06/2023 11:36:29 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "12/06/2023 11:36:29 - INFO - __main__ -   Total optimization steps = 3000\n",
            "Resuming from checkpoint checkpoint-2500\n",
            "12/06/2023 11:36:29 - INFO - accelerate.accelerator - Loading states from /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-2500\n",
            "12/06/2023 11:36:36 - INFO - accelerate.checkpointing - All model weights loaded successfully\n",
            "12/06/2023 11:36:39 - INFO - accelerate.checkpointing - All optimizer states loaded successfully\n",
            "12/06/2023 11:36:39 - INFO - accelerate.checkpointing - All scheduler states loaded successfully\n",
            "12/06/2023 11:36:39 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully\n",
            "12/06/2023 11:36:39 - INFO - accelerate.checkpointing - All random states loaded successfully\n",
            "12/06/2023 11:36:39 - INFO - accelerate.accelerator - Loading in 0 custom states\n",
            "Steps: 100% 3000/3000 [31:45<00:00,  3.80s/it, loss=0.199, lr=0.002]12/06/2023 12:08:25 - INFO - __main__ - Saving embeddings\n",
            "12/06/2023 12:08:25 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000\n",
            "12/06/2023 12:08:27 - INFO - accelerate.checkpointing - Model weights saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000/model.safetensors\n",
            "12/06/2023 12:08:29 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000/optimizer.bin\n",
            "12/06/2023 12:08:29 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000/scheduler.bin\n",
            "12/06/2023 12:08:29 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000/sampler.bin\n",
            "12/06/2023 12:08:29 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000/random_states_0.pkl\n",
            "12/06/2023 12:08:29 - INFO - __main__ - Saved state to /content/drive/MyDrive/cs236 project cornell/textual_inversion_bad11khand/checkpoint-3000\n",
            "Steps: 100% 3000/3000 [31:49<00:00,  3.80s/it, loss=0.0102, lr=0.002]12/06/2023 12:08:29 - INFO - __main__ - Saving embeddings\n",
            "Steps: 100% 3000/3000 [31:49<00:00,  3.82s/it, loss=0.0102, lr=0.002]\n"
          ]
        }
      ]
    }
  ]
}